{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c453fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage as ski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7d814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img0 = ski.io.imread('webreg_0.jpg')\n",
    "img1 = ski.io.imread('webreg_1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020030bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(1, 2,\n",
    "                             figsize=(9, 5))\n",
    "ax0.imshow(img0)\n",
    "ax1.imshow(img1)\n",
    "fig.suptitle('Click 4 matching coordinates; first left image, then right')\n",
    "\n",
    "coords = []\n",
    "\n",
    "def onclick(event):\n",
    "    coords.append((event.xdata, event.ydata))\n",
    "    \n",
    "    pcoords = np.array(coords)\n",
    "    \n",
    "    ax0.plot(pcoords[::2, 0], pcoords[::2, 1], 'rx')\n",
    "    ax1.plot(pcoords[1::2, 0], pcoords[1::2, 1], 'wx')\n",
    "    \n",
    "callback = fig.canvas.mpl_connect('button_press_event', onclick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fada395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = np.array(coords)\n",
    "source = coords[::2]\n",
    "target = coords[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8033a24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = ski.transform.estimate_transform('affine', source, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d48f619",
   "metadata": {},
   "source": [
    "Our goal now is to warp the second image and to blend it with the first.\n",
    "\n",
    "To better display the result (i.e. so pieces of the warped image don't get cropped), we will position both images on a 600x600 canvas.\n",
    "\n",
    "We use a translation transform to position the images on the canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c45fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = ski.transform.AffineTransform(translation=(-200, -170))\n",
    "\n",
    "img0_warped = ski.transform.warp(img0, inverse_map=offset,\n",
    "                                 output_shape=(600, 600))\n",
    "\n",
    "img1_warped = ski.transform.warp(img1, inverse_map=offset + tf,\n",
    "                                 output_shape=(600, 600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3bfacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find where both images overlap; in that region average their values\n",
    "mask = (img0_warped != 0) & (img1_warped != 0)\n",
    "registered = img0_warped + img1_warped\n",
    "registered[mask] /= 2\n",
    "\n",
    "# Display the results\n",
    "f, (ax0) = plt.subplots(1, 1, subplot_kw={'xticks': [], 'yticks': []}, figsize=(9, 9))\n",
    "ax0.imshow(registered);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b43db78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('py38': venv)",
   "language": "python",
   "name": "python38364bitpy38venv20f150ce32684001ab05c8062e826bc6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
