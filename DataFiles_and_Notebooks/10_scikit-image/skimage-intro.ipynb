{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/skimage_logo.png\" style=\"float: left;\"/>\n",
    "<div style=\"clear: both;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Homepage](http://skimage.org)\n",
    "- [Documentation](http://scikits-image.org/docs/dev/)\n",
    "- [Gallery](http://scikits-image.org/docs/dev/auto_examples/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schedule:\n",
    "\n",
    "- This notebook / breakouts\n",
    "- [Processing large images using dask](dask_ghosting.ipynb)\n",
    "- [RANSAC / breakout](ransac.ipynb)\n",
    "- Q&A\n",
    "- [Asteroid breakout](asteroid/asteroid_breakout.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skimage as ski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ecosystem\n",
    "\n",
    "<img src=\"img_proc_stack.svg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [skimage API reference](https://scikit-image.org/docs/stable/api/api.html)\n",
    "- [ndimage docs](http://docs.scipy.org/doc/scipy/reference/ndimage.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-world example: counting grains and bubbles\n",
    "\n",
    "This Scanning Element Microscopy image shows a glass sample\n",
    "(light gray matrix) with some bubbles (black) and unmolten\n",
    "sand grains (dark gray). We wish to determine the fraction\n",
    "of the sample covered by these three phases,\n",
    "and to estimate the number of sand grains and bubbles,\n",
    "their average sizes, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = np.flipud(plt.imread('bubbles.jpg'))\n",
    "img = plt.imread('bubbles.jpg')\n",
    "plt.imshow(img, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove banner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_clean = img[:880, :]\n",
    "plt.imshow(img_clean, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter to get rid of speckles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note matplotlib default colormap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.arange(12).reshape((3, 4))\n",
    "print(x)\n",
    "plt.imshow(x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_med = ndi.median_filter(img_clean, size=5)\n",
    "plt.imshow(img_med, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find threshold values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't do this\n",
    "# plt.hist(img_med, bins=40, range=(0, 150));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(img_med.flatten(), bins=40, range=(0, 150));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate layers by thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubbles = (img_med <= 50)\n",
    "sand = (img_med > 50) & (img_med <= 120)\n",
    "glass = (img_med > 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(layers, labels=None, cmap=plt.cm.gray):\n",
    "    f, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    if labels is None:\n",
    "        labels = [''] * len(layers)\n",
    "    \n",
    "    for n, (name, image) in enumerate(zip(labels, layers)):\n",
    "        ax = axes[n]\n",
    "        ax.imshow(image, cmap=cmap)\n",
    "        ax.set_title(name)\n",
    "        ax.set_axis_off()\n",
    "        \n",
    "plot_images([img_med, bubbles, sand, glass],\n",
    "            labels=('Original', 'Bubbles', 'Sand', 'Glass'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layers_to_color(layers, background=(0, 0, 0)):\n",
    "    if not all(layer.shape == layers[0].shape for layer in layers):\n",
    "        raise ValueError(\"All input images must have the same shape\")\n",
    "    \n",
    "    # Create new empty color image, filled with the background color\n",
    "    all_layers = np.full((layers[0].shape[0],\n",
    "                          layers[0].shape[1], 3), background, dtype=float)\n",
    "    \n",
    "    # Grab as many colors as layers from the \"plasma\" colormap\n",
    "    N = len(layers)\n",
    "    colors = plt.cm.plasma(np.linspace(0, 1, N, endpoint=True))[..., :3]\n",
    "\n",
    "    # You shouldn't run this if layer isn't a mask\n",
    "    # -- otherwise we get fancy indexing instead of masking\n",
    "    if not all(layer.dtype == bool for layer in layers):\n",
    "        raise ValueError(\"All input layers must be binary masks\")\n",
    "    \n",
    "    for (color, layer) in zip(colors, layers):\n",
    "        all_layers[layer] = color\n",
    "\n",
    "    return all_layers\n",
    "\n",
    "\n",
    "color_layers = layers_to_color([bubbles, sand, glass], background=(0, 1, 0))\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax.imshow(color_layers);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.imshow(sand);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up shapes found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_denoised = [img.copy() for img in (bubbles, sand, glass)]\n",
    "\n",
    "for img in layers_denoised:\n",
    "    # Get rid of small artifacts, such as edge rings\n",
    "    img[:] = ndi.binary_opening(img, np.ones((5, 5)))\n",
    "    \n",
    "    # Remove tiny holes\n",
    "    img[:] = ndi.binary_closing(img, np.ones((5, 5)))\n",
    "    \n",
    "color_layers_denoised = layers_to_color(layers_denoised, background=(0, 1, 0))\n",
    "\n",
    "f, axes = plt.subplots(2, 2, figsize=(20, 20))\n",
    "\n",
    "axes[0, 0].imshow(color_layers)\n",
    "axes[0, 1].imshow(color_layers_denoised)\n",
    "\n",
    "axes[1, 0].imshow(sand)\n",
    "axes[1, 1].imshow(layers_denoised[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label connected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubble_labels = np.zeros_like(bubbles, dtype=int)\n",
    "sand_labels = np.zeros_like(sand, dtype=int)\n",
    "glass_labels = np.zeros_like(glass, dtype=int)\n",
    "\n",
    "for name, image, labels in [('Sand', sand, sand_labels),\n",
    "                          ('Bubbles', bubbles, bubble_labels),\n",
    "                          ('Glass', glass, glass_labels)]:\n",
    "    \n",
    "    labels[:], count = ski.measure.label(image, return_num=True)    \n",
    "    \n",
    "    obj_areas = [np.sum(labels == i) \\\n",
    "                 for i in range(1, labels.max() + 1)]\n",
    "    µ = np.mean(obj_areas)\n",
    "    σ = np.std(obj_areas)\n",
    "    total = np.sum(obj_areas)\n",
    "    \n",
    "    print(f'''{name}:\n",
    "    {count} regions, µ = {µ:.1f} σ = {σ:.1f} pixels, Σ = {total:d}\n",
    "    ''')\n",
    "    \n",
    "plot_images([img_med] + \n",
    "            [label2rgb(labels, image=img_med) for labels in(bubble_labels, sand_labels, glass_labels)],\n",
    "            labels=('Original', 'Bubble labels', 'Sand labels', 'Glass labels'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, image, labels in [('Sand', sand, sand_labels),\n",
    "                          ('Bubbles', bubbles, bubble_labels),\n",
    "                          ('Glass', glass, glass_labels)]:\n",
    "        \n",
    "        # Approximates areas more accurately\n",
    "        \n",
    "        regions = ski.measure.regionprops(labels)\n",
    "        areas = [r.area for r in regions]\n",
    "        \n",
    "        print('µ = ', np.mean(areas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load http://scikit-image.org/docs/dev/_downloads/plot_blob.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gallery example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Paste any gallery example, such as http://scikit-image.org/docs/dev/_downloads/plot_equalize.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File input/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ski.io.imread('bubbles.jpg')\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter widgets for simple image browser\n",
    "\n",
    "#### Install widgets as follows:\n",
    "\n",
    "With conda:\n",
    "\n",
    "```\n",
    "conda install -c conda-forge ipywidgets\n",
    "```\n",
    "\n",
    "With pip, at the terminal, with the correct virtual environment enabled:\n",
    "\n",
    "```\n",
    "pip install ipywidgets\n",
    "```\n",
    "\n",
    "See https://ipywidgets.readthedocs.io/en/latest/user_install.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example images\n",
    "\n",
    "These ship with scikit-image, and are accessed using `skimage.data.*`.\n",
    "\n",
    "See https://scikit-image.org/docs/stable/auto_examples/index.html#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "skimage.data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nowadays, `skimage.data` also contains a bunch of examples that are too large to ship with the library,\n",
    "so they are downloaded upon use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic = ski.io.ImageCollection(skimage.data_dir + '/*.png')\n",
    "len(ic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "@interact(n=IntSlider(min=0, max=len(ic) - 1, continuous_update=False))\n",
    "def gallery(n=0):\n",
    "    plt.imshow(ic[n], cmap='gray', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "image = ski.color.rgb2gray(data.hubble_deep_field())\n",
    "\n",
    "@interact(sigma=FloatSlider(min=0.1, max=10, step=0.1, continuous_update=False))\n",
    "def filter_image(sigma=1):\n",
    "    f, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    ax.imshow(\n",
    "        filters.gaussian(image, sigma=sigma),\n",
    "        cmap='gray'\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we illustrate how to load FITS files.  You'll need `astropy` installed to try this.\n",
    "\n",
    "From https://en.wikipedia.org/wiki/FITS\n",
    "\n",
    "> The FITS standard was designed specifically for astronomical data, and includes provisions such as describing photometric and spatial calibration information, together with image origin metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "fits_image = fits.open('ngc7635_041008_15i75m_L.FIT')\n",
    "fits_image.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_image[0].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngc7635 = fits_image[0].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have `astropy` installed, use the following instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage import img_as_uint\n",
    "# from skimage import color\n",
    "#\n",
    "# ngc7635 = img_as_uint(color.rgb2gray(data.hubble_deep_field()))\n",
    "# \n",
    "# plt.imshow(ngc7635, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ngc7635, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data types and ranges\n",
    "\n",
    "[Data-type documentation](http://scikit-image.org/docs/dev/user_guide/data_types.html)\n",
    "\n",
    "NOTE: We are working to change the restrictions on data ranges for floating point images. Many functions now have a `preserve_range` flag.  In skimage2, this will be the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ngc7635.dtype)\n",
    "print(ngc7635.min(), ngc7635.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "out = ski.filters.gaussian(ngc7635, sigma=10)\n",
    "\n",
    "print(out.dtype, out.min(), out.max())\n",
    "\n",
    "plt.imshow(out, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "ngc7635_ = ski.exposure.rescale_intensity(ngc7635, in_range=(0, 16000))\n",
    "print(ngc7635_.dtype, ngc7635_.min(), ngc7635_.max())\n",
    "plt.imshow(ngc7635_, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion functions\n",
    "from skimage import img_as_float, img_as_int, img_as_ubyte\n",
    "\n",
    "print(img_as_float(ngc7635_).max())\n",
    "print(img_as_int(ngc7635_).max())\n",
    "print(img_as_ubyte(ngc7635_).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ski.data.camera());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ski.data.hubble_deep_field());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a pipeline\n",
    "\n",
    "In ``skimage``, functions should take any data-type image as input, but produce whichever data-type\n",
    "output it can generate most efficiently.  This means that you can always build pipelines (i.e. apply an skimage function to the output of another).\n",
    "\n",
    "E.g., let's combine denoising and edge detection:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- http://scikit-image.org/docs/dev/api/skimage.restoration.html#skimage.restoration.denoise_tv_bregman\n",
    "- http://scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature, restoration\n",
    "\n",
    "def pipeline(image):\n",
    "   return feature.canny(\n",
    "       restoration.denoise_tv_bregman(image, weight=1),\n",
    "       sigma=5\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data.camera()\n",
    "\n",
    "f, (ax0, ax1) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax0.imshow(img, cmap='gray')\n",
    "ax1.imshow(pipeline(img), cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometric Transformations\n",
    "\n",
    "Note: for historic reasons, the geometric transformations module uses `xy` coordinates instead of `row-column`.\n",
    "This, also, will change in skimage2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ski.transform.EuclideanTransform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.deg2rad(30)\n",
    "s = 0.8\n",
    "tx, ty = 150, 0\n",
    "\n",
    "tf = ski.transform.EuclideanTransform(rotation=theta, translation=(tx, ty))\n",
    "\n",
    "img = ski.data.camera()\n",
    "out = ski.transform.warp(img, tf.inverse)\n",
    "\n",
    "print(\"Let's send a coordinate through the transformation by hand:\")\n",
    "print(\"Origin maps to ->\", tf([0, 0]))\n",
    "print(\"Coordinate [150, 0] maps back to ->\", tf.inverse([150, 0]))\n",
    "\n",
    "f, (ax0, ax1) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax0.imshow(img, cmap=plt.cm.gray)\n",
    "ax1.imshow(out, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-linear warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import transform\n",
    "\n",
    "image = data.chelsea()\n",
    "\n",
    "def fisheye(xy, p=2.3, k=2.1, R=0.95, center=None):\n",
    "    if center is None:\n",
    "        center = np.mean(xy, axis=0)\n",
    "    xc, yc = (xy - center).T\n",
    "    \n",
    "    # Polar coordinates\n",
    "    r = np.sqrt(xc**2 + yc**2)\n",
    "    theta = np.arctan2(yc, xc)\n",
    "\n",
    "    r = R * np.exp(r**(1/p) / k)\n",
    "\n",
    "    return np.column_stack((\n",
    "        r * np.cos(theta), r * np.sin(theta)\n",
    "        )) + center \n",
    "\n",
    "out = transform.warp(image, fisheye,\n",
    "                     map_args={'p': 2.3, 'center': (250, 230), 'R': 1})\n",
    "\n",
    "f, (ax0, ax1) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax0.imshow(image)\n",
    "ax1.imshow(out);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Block views and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ski.data.camera()\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct rolling window over image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = ski.util.view_as_windows(img, window_shape=(20, 20))\n",
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_max = w.max(axis=2).max(axis=2)\n",
    "print(img_max.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_max);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same can now be achieved using Dask: [demo](dask_ghosting.ipynb)\n",
    "\n",
    "See also `ski.util.view_as_blocks` for non-overlapping views."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature detection: histogram of gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See, e.g. https://iq.opengenus.org/object-detection-with-histogram-of-oriented-gradients-hog/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = ski.data.camera()\n",
    "\n",
    "fd, hog_image = ski.feature.hog(image, orientations=16, pixels_per_cell=(16, 16),\n",
    "                                cells_per_block=(1, 1), visualize=True, block_norm='L2-Hys')\n",
    "\n",
    "# Rescale histogram for better display\n",
    "hog_image_rescaled = ski.exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "\n",
    "f, (ax0, ax1) = plt.subplots(1, 2, figsize=(15, 10))\n",
    "\n",
    "ax0.set_axis_off()\n",
    "ax0.imshow(image, cmap=plt.cm.gray)\n",
    "ax0.set_title('Input image')\n",
    "\n",
    "ax1.set_axis_off()\n",
    "ax1.imshow(hog_image_rescaled, cmap=plt.cm.gray)\n",
    "ax1.set_title('Histogram of Oriented Gradients')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breakout\n",
    "\n",
    "Please pick one of the following problems to work on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image registration\n",
    "\n",
    "Consider two satellite views of the same area:\n",
    "\n",
    "<pre>\n",
    "webreg_0.jpg webreg_1.jpg\n",
    "</pre>\n",
    "\n",
    "1. Load and display the images.\n",
    "2. Find coordinates that correspond between these images.\n",
    "   (See notebook cell below how to do that.)\n",
    "3. Using these sets of corresponding coordinates, fit an affine transform:\n",
    "   `skimage.transform.AffineTransform`.\n",
    "4. Apply the transform and then overlay the two images.\n",
    "\n",
    "Hints:\n",
    "\n",
    " - Look at ``skimage.transform``, specifically ``skimage.transform.warp``.\n",
    "\n",
    "The process of aligning and combining images is known as \"image registration\".\n",
    "\n",
    "For a much more detailed panoramic stitching example, see\n",
    "\n",
    "https://github.com/scikit-image/skimage-tutorials/blob/master/lectures/solutions/adv3_panorama-stitching-solution.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Here is how to pick coordinates inside of a Jupyter notebook:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This only works when you add\n",
    "#\n",
    "#  %matplotlib inline\n",
    "#\n",
    "# in the beginning of the notebook, to make matplotlib interactive\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2,\n",
    "                             figsize=(9, 5))\n",
    "ax0.imshow(img0)\n",
    "ax1.imshow(img1)\n",
    "fig.suptitle('Click 4 matching coordinates; first left image, then right')\n",
    "\n",
    "coords = []\n",
    "\n",
    "def onclick(event):\n",
    "    coords.append((event.xdata, event.ydata))\n",
    "    \n",
    "    pcoords = np.array(coords)\n",
    "    \n",
    "    ax0.plot(pcoords[::2, 0], pcoords[::2, 1], 'rx')\n",
    "    ax1.plot(pcoords[1::2, 0], pcoords[1::2, 1], 'wx')\n",
    "    \n",
    "callback = fig.canvas.mpl_connect('button_press_event', onclick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False-color image representation\n",
    "\n",
    "Consider the provided image files:\n",
    "\n",
    "<pre>\n",
    "  m8_050507_26i26m_L.png  m8_050507_9i9m_B.png  m8_050507_9i9m_R.png\n",
    "  m8_050507_5i75m_H.png   m8_050507_9i9m_G.png\n",
    "</pre>\n",
    "\n",
    "1. Load and display the individual inputs\n",
    "2. Add the inputs together to form a single grey-level image `(L + H + R + G + B)`.  Displaying\n",
    "   this image gives you an idea for all the information at your disposal.\n",
    "3. Now, combine these images into a single color  image.  Apply denoising as\n",
    "   as you see fit.  A real-world example pipeline is given here:\n",
    "\n",
    "  http://www.mistisoftware.com/astronomy/Process_m8.htm\n",
    "\n",
    "Hints:\n",
    "\n",
    " - These images are enormous--scale them down before playing around.\n",
    " - It may sometimes be easier to manipulate image colors in the Hue-Saturation-Value (HSV) colorspace.  Use `skimage.color.rgb2hsv` and `skimage.color.hsv2rgb`.\n",
    " - A colour image has dimensions ``(M, N, 3)`` for red, green and blue layers.\n",
    " - Bonus: to explore parameters, consider experimenting with Jupyter widget sliders."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "widgets": {
   "state": {
    "0bba7ce2f12544d9954fcef287f68b51": {
     "views": [
      {
       "cell_index": 43
      }
     ]
    },
    "eb24cb468ffc4028a21a8e4d97bb4fab": {
     "views": [
      {
       "cell_index": 38
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
